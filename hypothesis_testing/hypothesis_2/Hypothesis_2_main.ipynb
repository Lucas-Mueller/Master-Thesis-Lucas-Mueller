{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6811b8ad",
   "metadata": {},
   "source": [
    "# Hypothesis 2 — Main Notebook\n",
    "\n",
    "Hypothesis: The underlying LLM of an MAAI statistically significantly affects its fairness judgments; specifically, American and Chinese LLMs differ in their judgments.\n",
    "\n",
    "This notebook prepares two groups of aligned experiment configurations (American, Chinese),\n",
    "runs them selectively in parallel, and compares the outcome distributions across groups (5 categories).\n",
    "\n",
    "- 34 configs per group (default), total 68.\n",
    "- Per-config: a shared temperature drawn from U(0, 1.5), shared random seed, and agent models selected per group.\n",
    "- Language is English for all runs.\n",
    "- Utility agent is `gemini-2.5-flash`.\n",
    "- Voting detection mode is set to \"complex\" for all runs.\n",
    "- Exact test: Fisher–Freeman–Halton via R (if available). No Chi-square fallback.\n",
    "- Effect size: Cramér's V (bias-corrected, as in Hypothesis 1).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcfd22e",
   "metadata": {},
   "source": [
    "# 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "318e4295",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys, os\n",
    "from pathlib import Path\n",
    "\n",
    "# Ensure repo root on sys.path (for local package imports)\n",
    "def _add_repo_root_to_sys_path():\n",
    "    here = Path.cwd().resolve()\n",
    "    for p in [here] + list(here.parents):\n",
    "        if (p / 'main.py').exists() and (p / 'hypothesis_testing').is_dir():\n",
    "            if str(p) not in sys.path:\n",
    "                sys.path.insert(0, str(p))\n",
    "            return p\n",
    "    return here\n",
    "_REPO_ROOT = _add_repo_root_to_sys_path()\n",
    "\n",
    "import json\n",
    "import random\n",
    "import shutil\n",
    "import yaml\n",
    "from collections import Counter\n",
    "from hypothesis_testing.utils_hypothesis_testing.runner import (\n",
    "    list_config_files,\n",
    "    select_configs,\n",
    "    run_configs_in_parallel,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad00c84",
   "metadata": {},
   "source": [
    "# 2. Model Selection Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff82d287",
   "metadata": {},
   "source": [
    "## Data Import & Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9938001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file into a pandas dataframe\n",
    "# Data scraped from https://artificialanalysis.ai/leaderboards/models on 2025-10-08\n",
    "df = pd.read_csv(\"model_overview_artificial_analysis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "798e7e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove '€' symbol and spaces, replace comma with dot, and convert to float\n",
    "df['Price (Blended EUR/1M Tokens)'] = df['Price (Blended EUR/1M Tokens)'].str.replace('€', '').str.strip().str.replace(',', '.').astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4003395d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s = df['Context Window'].astype(str).str.strip().str.lower()\n",
    "m = s.str.extract(r'^\\s*(\\d+(?:[.,]\\d+)?)\\s*([km]?)\\s*$')\n",
    "num = pd.to_numeric(m[0].str.replace(',', '.', regex=False), errors='coerce')\n",
    "mult = m[1].map({'k': 1_000, 'm': 1_000_000}).fillna(1)\n",
    "df['Context Window'] = num * mult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "848bb7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Latency First Answer Chunk (s) (replace comma with dot)\n",
    "df['Latency First Answer Chunk (s)'] = (\n",
    "    df['Latency First Answer Chunk (s)']\n",
    "      .astype(str)\n",
    "      .str.replace(',', '.', regex=False)\n",
    "      .astype(float)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7aa7d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for models with price less than 0.5 EUR per 1M tokens to reduce cost\n",
    "df_cheap = df[df['Price (Blended EUR/1M Tokens)'] < 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1489178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by Intelligence Index (Artificial Analysis Index)\n",
    "df_cheap= df_cheap.sort_values(by=[\"Intelligence Index\"], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70122be4",
   "metadata": {},
   "source": [
    "## Creating Final Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b22991f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Context Window</th>\n",
       "      <th>Creator</th>\n",
       "      <th>Country</th>\n",
       "      <th>Intelligence Index</th>\n",
       "      <th>Price (Blended EUR/1M Tokens)</th>\n",
       "      <th>Speed (Median Tokens/s)</th>\n",
       "      <th>Latency First Answer Chunk (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>DeepSeek V3.2 Exp</td>\n",
       "      <td>128000</td>\n",
       "      <td>DeepSeek</td>\n",
       "      <td>China</td>\n",
       "      <td>57</td>\n",
       "      <td>0.28</td>\n",
       "      <td>25</td>\n",
       "      <td>1.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>GLM-4.5-Air</td>\n",
       "      <td>128000</td>\n",
       "      <td>Z AI</td>\n",
       "      <td>China</td>\n",
       "      <td>49</td>\n",
       "      <td>0.36</td>\n",
       "      <td>210</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Qwen3 Omni 30B A3B</td>\n",
       "      <td>66000</td>\n",
       "      <td>Alibaba</td>\n",
       "      <td>China</td>\n",
       "      <td>40</td>\n",
       "      <td>0.37</td>\n",
       "      <td>88</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Context Window   Creator Country  Intelligence Index  \\\n",
       "15   DeepSeek V3.2 Exp          128000  DeepSeek   China                  57   \n",
       "28         GLM-4.5-Air          128000      Z AI   China                  49   \n",
       "53  Qwen3 Omni 30B A3B           66000   Alibaba   China                  40   \n",
       "\n",
       "    Price (Blended EUR/1M Tokens)  Speed (Median Tokens/s)  \\\n",
       "15                           0.28                       25   \n",
       "28                           0.36                      210   \n",
       "53                           0.37                       88   \n",
       "\n",
       "    Latency First Answer Chunk (s)  \n",
       "15                            1.35  \n",
       "28                            0.66  \n",
       "53                            0.97  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting the Chinese Models for the analysis\n",
    "\n",
    "# Filtering by Chinese models\n",
    "df_chinese = df_cheap[df_cheap[\"Country\"] == \"China\"]\n",
    "\n",
    "# Removing models which are not properly accesible through API\n",
    "df_chinese = df_chinese[df_chinese[\"Speed (Median Tokens/s)\"]>0]\n",
    "\n",
    "#Selecting 6 best models by Articialy Intelligence Index\n",
    "df_chinese_select = df_chinese[:3]\n",
    "\n",
    "\n",
    "\n",
    "# List of Chinese models\n",
    "chinese_models = df_chinese_select[\"Model\"].tolist()\n",
    "\n",
    "df_chinese_select.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95672557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the American Models\n",
    "df_american = df_cheap[df_cheap[\"Country\"] == \"USA\"] \n",
    "df_american = df_american.copy()\n",
    "# Remove Llama Nemotron Super 49B v1.5 and Gemini 2.5 Flash-Lite (Sep) (reasoning) since they are not accessible through the Open Router API\n",
    "df_american.drop(df[df[\"Model\"] == \"Llama Nemotron Super 49B v1.5\"].index, inplace=True)\n",
    "df_american.drop(df[df[\"Model\"] == \"Gemini 2.5 Flash-Lite (Sep) (reasoning)\"].index, inplace=True)\n",
    "\n",
    "df_american = df_american[df_american[\"Speed (Median Tokens/s)\"]>0]\n",
    "\n",
    "# Exclude GPT 5 models since they do not support temperature\n",
    "df_american = df_american[~df_american[\"Model\"].str.contains(r\"gpt[-\\s]*5\", case=False, na=False)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "grok_inserted_cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 Chinese LLMs:\n",
      "                 Model  Intelligence Index\n",
      "15   DeepSeek V3.2 Exp                  57\n",
      "28         GLM-4.5-Air                  49\n",
      "53  Qwen3 Omni 30B A3B                  40\n",
      "\n",
      "Matched American LLMs:\n",
      "                  Model  Intelligence Index\n",
      "12  gpt-oss-120B (high)                  58\n",
      "29     Grok Code Fast 1                  49\n",
      "54          Grok 4 Fast                  39\n"
     ]
    }
   ],
   "source": [
    "# Select top 3 Chinese LLMs by Intelligence Index\n",
    "top_3_chinese = df_chinese_select.head(3)\n",
    "print(\"Top 3 Chinese LLMs:\")\n",
    "print(top_3_chinese[['Model', 'Intelligence Index']])\n",
    "\n",
    "# Get their scores\n",
    "top_scores = top_3_chinese['Intelligence Index'].values\n",
    "\n",
    "# For each score, find the closest American Models so that there is not delta in Intelligence Index\n",
    "matched_americans = []\n",
    "for score in top_scores:\n",
    "    df_american_copy = df_american.copy()\n",
    "    df_american_copy['diff'] = abs(df_american_copy['Intelligence Index'] - score)\n",
    "    closest_idx = df_american_copy['diff'].idxmin()\n",
    "    closest = df_american_copy.loc[closest_idx]\n",
    "    matched_americans.append(closest)\n",
    "\n",
    "# Create DataFrame\n",
    "matched_df = pd.DataFrame(matched_americans)\n",
    "print(\"\\nMatched American LLMs:\")\n",
    "print(matched_df[['Model', 'Intelligence Index']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b53cb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_models = matched_df[\"Model\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16d7f2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gpt-oss-120B (high)', 'Grok Code Fast 1', 'Grok 4 Fast']\n"
     ]
    }
   ],
   "source": [
    "print(us_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31449df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DeepSeek V3.2 Exp', 'GLM-4.5-Air', 'Qwen3 Omni 30B A3B']\n"
     ]
    }
   ],
   "source": [
    "print(chinese_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04491ad",
   "metadata": {},
   "source": [
    "## Retrieval of OpenRouter IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "496609f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lookup = {\n",
    "\"DeepSeek V3.2 Exp\": \"deepseek/deepseek-v3.2-exp\",\n",
    "\"GLM-4.5-Air\": \"z-ai/glm-4.5-air\",\n",
    "\"Qwen3 Omni 30B A3B\": \"qwen/qwen3-next-80b-a3b-thinking\",\n",
    "\"gpt-oss-120B (high)\": \"openai/gpt-oss-120b\",\n",
    "\"Grok Code Fast 1\": \"x-ai/grok-code-fast-1\",\n",
    "\"Grok 4 Fast\": \"x-ai/grok-4-fast\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf14557e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepSeek V3.2 Exp: deepseek/deepseek-v3.2-exp\n",
      "GLM-4.5-Air: z-ai/glm-4.5-air\n",
      "Qwen3 Omni 30B A3B: qwen/qwen3-next-80b-a3b-thinking\n"
     ]
    }
   ],
   "source": [
    "CHINESE_MODELS = []\n",
    "for model in chinese_models:\n",
    "    if model in model_lookup:\n",
    "        print(f\"{model}: {model_lookup[model]}\")\n",
    "        CHINESE_MODELS.append(model_lookup[model])\n",
    "    else:\n",
    "        print(f\"{model}: Not found in lookup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f231ad86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-oss-120B (high): openai/gpt-oss-120b\n",
      "Grok Code Fast 1: x-ai/grok-code-fast-1\n",
      "Grok 4 Fast: x-ai/grok-4-fast\n"
     ]
    }
   ],
   "source": [
    "AMERICAN_MODELS = []\n",
    "for model in us_models:\n",
    "    if model in model_lookup:\n",
    "        print(f\"{model}: {model_lookup[model]}\")\n",
    "        AMERICAN_MODELS.append(model_lookup[model])\n",
    "    else:\n",
    "        print(f\"{model}: Not found in lookup\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3acd04",
   "metadata": {},
   "source": [
    "# 3) Config Generation\n",
    "\n",
    "Generates aligned YAML configurations for each group.\n",
    "- Language is English for all runs.\n",
    "- Utility agent: `gemini-2.5-flash`.\n",
    "- Voting detection mode: `complex`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e616e507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('/Users/lucasmuller/Desktop/Githubg/Rawls_v3/hypothesis_testing/hypothesis_2/configs'),\n",
       " PosixPath('/Users/lucasmuller/Desktop/Githubg/Rawls_v3/hypothesis_testing/hypothesis_2/terminal_outputs'),\n",
       " PosixPath('/Users/lucasmuller/Desktop/Githubg/Rawls_v3/hypothesis_testing/hypothesis_2/results'),\n",
       " PosixPath('/Users/lucasmuller/Desktop/Githubg/Rawls_v3/hypothesis_testing/hypothesis_2/transcripts'),\n",
       " {'american': 'American LLMs', 'chinese': 'Chinese LLMs'})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Base paths and groups\n",
    "BASE_DIR = _REPO_ROOT / 'hypothesis_testing' / 'hypothesis_2'\n",
    "CONFIGS_BASE = BASE_DIR / 'configs'\n",
    "LOGS_BASE = BASE_DIR / 'terminal_outputs'\n",
    "RESULTS_BASE = BASE_DIR / 'results'\n",
    "TRANSCRIPTS_BASE = BASE_DIR / 'transcripts'\n",
    "\n",
    "GROUPS = {\n",
    "    'american': 'American LLMs',\n",
    "    'chinese': 'Chinese LLMs',\n",
    "}\n",
    "\n",
    "# Ensure subfolders exist\n",
    "for key in GROUPS.keys():\n",
    "    (CONFIGS_BASE / key).mkdir(parents=True, exist_ok=True)\n",
    "    (LOGS_BASE / key).mkdir(parents=True, exist_ok=True)\n",
    "    (RESULTS_BASE / key).mkdir(parents=True, exist_ok=True)\n",
    "    (TRANSCRIPTS_BASE / key).mkdir(parents=True, exist_ok=True)\n",
    "CONFIGS_BASE, LOGS_BASE, RESULTS_BASE, TRANSCRIPTS_BASE, GROUPS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f348f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'american': 33, 'chinese': 33}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Income class probabilities (must sum to 1.0)\n",
    "INCOME_CLASS_PROBS = {\n",
    "    'high': 0.05,\n",
    "    'medium_high': 0.10,\n",
    "    'medium': 0.50,\n",
    "    'medium_low': 0.25,\n",
    "    'low': 0.10,\n",
    "}\n",
    "\n",
    "# American and Chinese model pools (OpenRouter IDs)\n",
    "\n",
    "def make_agents_with_models(temp: float, models: list[str]) -> list[dict]:\n",
    "    agents = []\n",
    "    for i in range(0, 3):  # 3 participant agents\n",
    "        agents.append({\n",
    "            'name': f'Agent_{i+1}',\n",
    "            'personality': 'You are a college student',\n",
    "            'model': models[i],\n",
    "            'temperature': float(temp),\n",
    "            'memory_character_limit': 25000,\n",
    "            'reasoning_enabled': True,\n",
    "        })\n",
    "    return agents\n",
    "\n",
    "def build_config(temp: float, models: list[str]) -> dict:\n",
    "    return {\n",
    "        'language': 'English',\n",
    "        'agents': make_agents_with_models(temp, models),\n",
    "        'utility_agent_model': 'gemini-2.0-flash-lite',\n",
    "        'utility_agent_temperature': 0.0,\n",
    "        'phase2_rounds': 10,\n",
    "        'distribution_range_phase2': [2, 6],\n",
    "        'income_class_probabilities': INCOME_CLASS_PROBS,\n",
    "        'original_values_mode': { 'enabled': True },\n",
    "        'transcript_logging': { 'enabled': True },\n",
    "        'logging': {\"verbosity_level\": \"debug\"}  # or minimal, detailed, debug\n",
    "\n",
    "        \n",
    "    }\n",
    "\n",
    "def _pick_american_models() -> list[str]:\n",
    "    # Allow repeats; sample each agent independently\n",
    "    return [random.choice(AMERICAN_MODELS) for _ in range(4)]\n",
    "\n",
    "def _pick_chinese_models() -> list[str]:\n",
    "    return [random.choice(CHINESE_MODELS) for _ in range(4)]\n",
    "\n",
    "def generate_aligned_configs(n: int = 33) -> dict[str, list[Path]]:\n",
    "    paths: dict[str, list[Path]] = {k: [] for k in GROUPS.keys()}\n",
    "    for idx in range(1, n + 1):\n",
    "            # FIXED: First 11 configs have temp = 0, rest have random temp\n",
    "            if idx <= 11:\n",
    "                temp = 0.0\n",
    "            else:\n",
    "                temp = random.uniform(0.0, 1.0) # Temperature between 0.0 and 1.0, lower value than in Hpyothesis 1 since the models here are less smart and therfore have a higher risk to fail\n",
    "\n",
    "            # Build per-group models\n",
    "            models_american = _pick_american_models()\n",
    "            models_chinese = _pick_chinese_models()\n",
    "\n",
    "            # Write configs\n",
    "            for group_key, models in [('american', models_american), ('chinese', models_chinese)]:\n",
    "                cfg = build_config(temp=temp,models=models)\n",
    "                out_dir = (CONFIGS_BASE / group_key)\n",
    "                out_dir.mkdir(parents=True, exist_ok=True)\n",
    "                fname = out_dir / f'hypothesis_2_{group_key}_condition_{idx}_config.yaml'\n",
    "                with open(fname, 'w') as f:\n",
    "                    yaml.safe_dump(cfg, f, sort_keys=False)\n",
    "                paths[group_key].append(fname)\n",
    "    return paths\n",
    "\n",
    "# Example (commented):\n",
    "#files_by_group = generate_aligned_configs(n=33)\n",
    "#{k: len(v) for k, v in files_by_group.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef508ce",
   "metadata": {},
   "source": [
    "# 4) Run Configs \n",
    "\n",
    "Select subsets and run with per-group logs/results directories.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95cd8efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_group(group_key: str, include_indices=None, include_names=None, concurrency: int = 4, timeout_sec: int | None = None):\n",
    "    cfg_dir = CONFIGS_BASE / group_key\n",
    "    logs_dir = LOGS_BASE / group_key\n",
    "    results_dir = RESULTS_BASE / group_key\n",
    "    configs = list_config_files(cfg_dir)\n",
    "    selected = select_configs(configs, include_indices=include_indices, include_names=include_names)\n",
    "    print(f'[{group_key}] Found {len(configs)} configs; selected {len(selected)}')\n",
    "    run_results = run_configs_in_parallel(\n",
    "        selected,\n",
    "        concurrency=concurrency,\n",
    "        logs_dir=logs_dir,\n",
    "        results_dir=results_dir,\n",
    "        timeout_sec=timeout_sec,\n",
    "    )\n",
    "    ok = sum(1 for r in run_results if r.get('ok'))\n",
    "    print(f'[{group_key}] Completed: {ok}/{len(run_results)} OK')\n",
    "    return run_results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9321139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[american] Found 34 configs; selected 34\n",
      "[american] Completed: 34/34 OK\n"
     ]
    }
   ],
   "source": [
    "#rr_us = run_group('american', include_indices=list(range(1, 34)) , concurrency=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6380da1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[chinese] Found 34 configs; selected 22\n",
      "[chinese] Completed: 13/22 OK\n"
     ]
    }
   ],
   "source": [
    "#rr_cn = run_group('chinese', include_indices=list(range(1,34)) , concurrency=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a90544e",
   "metadata": {},
   "source": [
    "## 3) Analysis — Compare Outcomes Across Groups\n",
    "\n",
    "Build a 5×2 contingency table (rows=principle/disagreement categories; columns=American/Chinese)\n",
    "and run Fisher–Freeman–Halton exact test via R when available.\n",
    "Compute Cramér's V with bias correction (as in Hypothesis 1). No Chi-square fallback is included.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3bbcce3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "American counts: {'maximizing_floor': 14, 'maximizing_average_floor_constraint': 15, 'disagreement': 4, 'maximizing_average': 0, 'maximizing_average_range_constraint': 0}\n",
      "Chinese counts: {'maximizing_average_floor_constraint': 21, 'maximizing_floor': 4, 'disagreement': 6, 'maximizing_average': 2, 'maximizing_average_range_constraint': 0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[14,  4],\n",
       "        [ 0,  2],\n",
       "        [15, 21],\n",
       "        [ 0,  0],\n",
       "        [ 4,  6]]),\n",
       " ['maximizing_floor',\n",
       "  'maximizing_average',\n",
       "  'maximizing_average_floor_constraint',\n",
       "  'maximizing_average_range_constraint',\n",
       "  'disagreement'],\n",
       " ['american', 'chinese'])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CATEGORIES = [\n",
    "    'maximizing_floor',\n",
    "    'maximizing_average',\n",
    "    'maximizing_average_floor_constraint',\n",
    "    'maximizing_average_range_constraint',\n",
    "    'disagreement',\n",
    "]\n",
    "\n",
    "def categorize_result(result_path: Path) -> str:\n",
    "    try:\n",
    "        with open(result_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        gi = data.get('general_information', {})\n",
    "        consensus = gi.get('consensus_reached', False)\n",
    "        principle = gi.get('consensus_principle')\n",
    "        if consensus and principle in CATEGORIES:\n",
    "            return principle\n",
    "        return 'disagreement'\n",
    "    except Exception:\n",
    "        return 'disagreement'\n",
    "\n",
    "def count_by_group() -> dict[str, Counter]:\n",
    "    out: dict[str, Counter] = {}\n",
    "    for k in GROUPS.keys():\n",
    "        counts = Counter()\n",
    "        result_files = sorted((RESULTS_BASE / k).glob('*_results.json'))\n",
    "        for rp in result_files:\n",
    "            counts[categorize_result(rp)] += 1\n",
    "        for cat in CATEGORIES:\n",
    "            counts.setdefault(cat, 0)\n",
    "        out[k] = counts\n",
    "    return out\n",
    "\n",
    "group_counts = count_by_group()\n",
    "for k, counts in group_counts.items():\n",
    "    print(f'{k.capitalize()} counts:', dict(counts))\n",
    "\n",
    "# Build contingency table: rows=categories, cols=[American, Chinese]\n",
    "col_order = ['american', 'chinese']\n",
    "contingency = np.vstack([[group_counts[col][cat] for col in col_order] for cat in CATEGORIES])\n",
    "contingency, CATEGORIES, col_order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "04916c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fisher–Freeman–Halton exact test p-value: 0.024749\n"
     ]
    }
   ],
   "source": [
    "def fisher_freeman_halton_pvalue_r(contingency: np.ndarray) -> float | None:\n",
    "    \"\"\"Run Fisher–Freeman–Halton test via R's fisher.test if available.\n",
    "    Returns p-value or None if Rscript not found or fails.\n",
    "    \"\"\"\n",
    "    if shutil.which('Rscript') is None:\n",
    "        return None\n",
    "    r_matrix = ','.join(str(int(x)) for x in contingency.flatten(order='C'))\n",
    "    nrow, ncol = contingency.shape\n",
    "    r_code = f\"\"\"m <- matrix(c({r_matrix}), nrow={nrow}, ncol={ncol}, byrow=TRUE);\n",
    "f <- tryCatch(fisher.test(m), error=function(e) NA);\n",
    "if (is.list(f)) cat(f$p.value) else cat('NA')\n",
    "\"\"\"\n",
    "    import subprocess\n",
    "    try:\n",
    "        out = subprocess.check_output(['Rscript', '-e', r_code], stderr=subprocess.STDOUT, text=True)\n",
    "        out = out.strip()\n",
    "        return float(out) if out and out != 'NA' else None\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "p_ffh = fisher_freeman_halton_pvalue_r(contingency)\n",
    "if p_ffh is None:\n",
    "    print('R not available; skipping Fisher–Freeman–Halton exact test')\n",
    "else:\n",
    "    print(f'Fisher–Freeman–Halton exact test p-value: {p_ffh:.6f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e93dc5bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cramér's V (uncorrected): 0.3684\n",
      "Cramér's V (bias-corrected): 0.3016\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "\n",
    "def _prune_empty_rows_cols(contingency: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Drop all-zero rows and columns to avoid degenerate shapes and expected=0 cells.\n",
    "    Returns the original array if nothing needs pruning.\n",
    "    \"\"\"\n",
    "    contingency = np.asarray(contingency, dtype=float)\n",
    "    if contingency.ndim != 2:\n",
    "        raise ValueError(\"contingency must be a 2D array\")\n",
    "\n",
    "    row_mask = contingency.sum(axis=1) > 0\n",
    "    col_mask = contingency.sum(axis=0) > 0\n",
    "\n",
    "    if row_mask.all() and col_mask.all():\n",
    "        return contingency\n",
    "    pruned = contingency[row_mask][:, col_mask]\n",
    "    return pruned\n",
    "\n",
    "\n",
    "def cramers_v(contingency: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Standard Cramér's V using Pearson's chi-square with NO Yates correction.\n",
    "    Matches the definition used by Bergsma (2013) before bias correction.\n",
    "    \"\"\"\n",
    "    tab = _prune_empty_rows_cols(contingency)\n",
    "    n = tab.sum()\n",
    "    if n <= 0:\n",
    "        return 0.0\n",
    "\n",
    "    r, c = tab.shape\n",
    "    df_min = min(r - 1, c - 1)\n",
    "    if df_min <= 0:\n",
    "        return 0.0\n",
    "\n",
    "    chi2, _, _, _ = chi2_contingency(tab, correction=False)\n",
    "    return float(np.sqrt((chi2 / n) / df_min))\n",
    "\n",
    "\n",
    "def bias_corrected_cramers_v(contingency: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Bergsma (2013) bias-corrected Cramér's V.\n",
    "    - Subtracts finite-sample bias for phi^2 at independence.\n",
    "    - Adjusts effective dimensions so the corrected measure can still reach 1.\n",
    "    Formulas:\n",
    "      phi2_corr = max(0, chi2/n - ((r-1)(c-1))/(n-1))\n",
    "      r_corr = r - ((r-1)^2)/(n-1)\n",
    "      c_corr = c - ((c-1)^2)/(n-1)\n",
    "      V_tilde = sqrt(phi2_corr / min(r_corr-1, c_corr-1))\n",
    "    \"\"\"\n",
    "    tab = _prune_empty_rows_cols(contingency)\n",
    "    n = tab.sum()\n",
    "    if n <= 1:\n",
    "        return 0.0\n",
    "\n",
    "    r, c = tab.shape\n",
    "    if min(r - 1, c - 1) <= 0:\n",
    "        return 0.0\n",
    "\n",
    "    chi2, _, _, _ = chi2_contingency(tab, correction=False)\n",
    "    phi2 = chi2 / n\n",
    "    r1, c1 = r - 1, c - 1\n",
    "\n",
    "    # Bias correction at independence\n",
    "    phi2_corr = max(0.0, phi2 - (r1 * c1) / (n - 1))\n",
    "\n",
    "    # Adjusted table dimensions\n",
    "    r_corr = r - (r1 * r1) / (n - 1)\n",
    "    c_corr = c - (c1 * c1) / (n - 1)\n",
    "    denom = min(r_corr - 1.0, c_corr - 1.0)\n",
    "    if denom <= 0.0:\n",
    "        return 0.0\n",
    "\n",
    "    return float(np.sqrt(phi2_corr / denom))\n",
    "\n",
    "\n",
    "def bootstrap_cramers_v(\n",
    "    contingency: np.ndarray,\n",
    "    n_bootstrap: int = 5000,\n",
    "    confidence_level: float = 0.95,\n",
    "    bias_corrected: bool = True,\n",
    "    seed: int | None = 123,\n",
    ") -> tuple[np.ndarray, float, float]:\n",
    "    \"\"\"\n",
    "    Nonparametric bootstrap for Cramér's V by resampling counts from the empirical\n",
    "    cell distribution via Multinomial(n, p). Uses percentile CI.\n",
    "\n",
    "    Returns:\n",
    "        (vs, lo, hi)\n",
    "        - vs: array of bootstrap V values\n",
    "        - lo, hi: lower/upper bounds of the (1 - alpha) percentile CI\n",
    "    \"\"\"\n",
    "    tab = np.asarray(contingency, dtype=float)\n",
    "    n = int(tab.sum())\n",
    "    if n <= 0:\n",
    "        return np.array([]), 0.0, 0.0\n",
    "    if not (0.0 < confidence_level < 1.0):\n",
    "        raise ValueError(\"confidence_level must be in (0, 1)\")\n",
    "\n",
    "    p = (tab / n).ravel()\n",
    "    idxs = np.arange(p.size)\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "    vs = np.empty(n_bootstrap, dtype=float)\n",
    "\n",
    "    for b in range(n_bootstrap):\n",
    "        # Draw a bootstrap table ~ Multinomial(n, p)\n",
    "        counts = rng.multinomial(n, p).reshape(tab.shape)\n",
    "        v = bias_corrected_cramers_v(counts) if bias_corrected else cramers_v(counts)\n",
    "        vs[b] = v\n",
    "\n",
    "    alpha = 1.0 - confidence_level\n",
    "    lo, hi = np.quantile(vs, [alpha / 2.0, 1.0 - alpha / 2.0])\n",
    "    return vs, float(lo), float(hi)\n",
    "\n",
    "\n",
    "cv = cramers_v(contingency)\n",
    "cv_corr = bias_corrected_cramers_v(contingency)\n",
    "print(f\"Cramér's V (uncorrected): {cv:.4f}\")\n",
    "print(f\"Cramér's V (bias-corrected): {cv_corr:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
