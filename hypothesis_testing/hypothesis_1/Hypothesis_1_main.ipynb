{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce1de810",
   "metadata": {},
   "source": [
    "# Hypothesis 1 — Main Notebook\n",
    "\n",
    "This notebook generates 33 experiment configurations, runs them in parallel with configurable concurrency and selection, logs outputs, and analyzes how often groups reach each of the four principles vs. disagreement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "817a7ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys, os\n",
    "from pathlib import Path\n",
    "\n",
    "# Ensure repo root on sys.path (for local package imports)\n",
    "def _add_repo_root_to_sys_path():\n",
    "    here = Path.cwd().resolve()\n",
    "    for p in [here] + list(here.parents):\n",
    "        if (p / 'main.py').exists() and (p / 'hypothesis_testing').is_dir():\n",
    "            if str(p) not in sys.path:\n",
    "                sys.path.insert(0, str(p))\n",
    "            return p\n",
    "    return here\n",
    "_REPO_ROOT = _add_repo_root_to_sys_path()\n",
    "\n",
    "import json\n",
    "import random\n",
    "import shutil\n",
    "import yaml\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency\n",
    "from hypothesis_testing.utils_hypothesis_testing.runner import (\n",
    "    list_config_files,\n",
    "    select_configs,\n",
    "    run_configs_in_parallel,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bc2ae8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('/Users/lucasmuller/Desktop/Githubg/Rawls_v3/hypothesis_testing/hypothesis_1/configs'),\n",
       " PosixPath('/Users/lucasmuller/Desktop/Githubg/Rawls_v3/hypothesis_testing/hypothesis_1/terminal_outputs'),\n",
       " PosixPath('/Users/lucasmuller/Desktop/Githubg/Rawls_v3/hypothesis_testing/hypothesis_1/results'),\n",
       " PosixPath('/Users/lucasmuller/Desktop/Githubg/Rawls_v3/hypothesis_testing/hypothesis_1/transcripts'))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configuration paths and constants\n",
    "CONFIG_DIR = _REPO_ROOT / 'hypothesis_testing' / 'hypothesis_1' / 'configs'\n",
    "TERMINAL_OUTPUTS_DIR   = _REPO_ROOT / 'hypothesis_testing' / 'hypothesis_1' / 'terminal_outputs'\n",
    "RESULTS_DIR= _REPO_ROOT / 'hypothesis_testing' / 'hypothesis_1' / 'results'\n",
    "TRANSCRIPTS_DIR = _REPO_ROOT / 'hypothesis_testing' / 'hypothesis_1' / 'transcripts'\n",
    "\n",
    "# Placeholder model list for participant agents\n",
    "\n",
    "MODEL_LIST = [\n",
    "    \"gemini-2.5-pro\",\n",
    "    \"gemini-2.5-flash\",\n",
    "    \"gemini-2.5-flash-lite\",\n",
    "]\n",
    "\n",
    "# Income class probabilities (must sum to 1.0)\n",
    "# Same as in Frohlich & Oppenheimer (1992) for the initial distribution\n",
    "INCOME_CLASS_PROBS = {\n",
    "    'high': 0.05,\n",
    "    'medium_high': 0.10,\n",
    "    'medium': 0.50,\n",
    "    'medium_low': 0.25,\n",
    "    'low': 0.10,\n",
    "}\n",
    "\n",
    "# Ensure directories exist\n",
    "CONFIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "TERMINAL_OUTPUTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "TRANSCRIPTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "CONFIG_DIR, TERMINAL_OUTPUTS_DIR, RESULTS_DIR, TRANSCRIPTS_DIR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fca35c",
   "metadata": {},
   "source": [
    "## 1. Generate 33 Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18548c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33,\n",
       " PosixPath('/Users/lucasmuller/Desktop/Githubg/Rawls_v3/hypothesis_testing/hypothesis_1/configs/hypothesis_1_condition_1_config.yaml'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_agents(temp: float, rng: random.Random) -> list[dict]:\n",
    "    agents = []\n",
    "    for i in range(0, 5):  # 5 participant agents\n",
    "        agents.append({\n",
    "            'name': f'Agent_{i+1}',\n",
    "            'personality': 'You are an American college student',\n",
    "            'model': rng.choice(MODEL_LIST),\n",
    "            'temperature': float(temp),\n",
    "            'memory_character_limit': 25000,\n",
    "            'reasoning_enabled': True,\n",
    "        })\n",
    "    return agents\n",
    "\n",
    "def build_config(temp: float, seed_val: int, rng: random.Random) -> dict:\n",
    "    return {\n",
    "        'language': 'English',\n",
    "        'seed': int(seed_val),\n",
    "        'agents': make_agents(temp, rng),\n",
    "        'utility_agent_model': 'gemini-2.0-flash-lite-001',\n",
    "        'utility_agent_temperature': 0.0,\n",
    "        'phase2_rounds': 10,\n",
    "        'distribution_range_phase2': [2, 6],\n",
    "        'income_class_probabilities': INCOME_CLASS_PROBS,\n",
    "        'original_values_mode': {'enabled': True},\n",
    "    }\n",
    "\n",
    "# Temperatures: 11 with 0, 11 with U(0,1), 11 with U(0,1.5)\n",
    "GLOBAL_SEED = 21000\n",
    "master_rng = random.Random(GLOBAL_SEED)  # deterministic config generation\n",
    "\n",
    "temps_fixed = [0.0] * 11\n",
    "temps_u01 = [master_rng.uniform(0.0, 1.0) for _ in range(11)]\n",
    "temps_u015 = [master_rng.uniform(0.0, 1.5) for _ in range(11)]\n",
    "all_temps = temps_fixed + temps_u01 + temps_u015\n",
    "\n",
    "generated_files = []\n",
    "for idx, temp in enumerate(all_temps, start=1):\n",
    "    seed_val = master_rng.randint(0, 2**31 - 1)\n",
    "    cfg_rng = random.Random(seed_val)  # tie agent sampling to the seed\n",
    "    cfg = build_config(temp=temp, seed_val=seed_val, rng=cfg_rng)\n",
    "    fname = CONFIG_DIR / f'hypothesis_1_condition_{idx}_config.yaml'\n",
    "    with open(fname, 'w') as f:\n",
    "        yaml.safe_dump(cfg, f, sort_keys=False)\n",
    "    generated_files.append(fname)\n",
    "\n",
    "len(generated_files), generated_files[0] if generated_files else None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54ed840",
   "metadata": {},
   "source": [
    "## 2. Run Configs (Parallel + Selective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98010b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 33 configs\n",
      "Selected 2 configs to run\n",
      "Completed: 2/2 OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'config': '/Users/lucasmuller/Desktop/Githubg/Rawls_v3/hypothesis_testing/hypothesis_1/configs/hypothesis_1_condition_15_config.yaml',\n",
       "  'log': '/Users/lucasmuller/Desktop/Githubg/Rawls_v3/hypothesis_testing/hypothesis_1/terminal_outputs/hypothesis_1_condition_15_log',\n",
       "  'result': '/Users/lucasmuller/Desktop/Githubg/Rawls_v3/hypothesis_testing/hypothesis_1/results/hypothesis_1_condition_15_config_results.json',\n",
       "  'returncode': 0,\n",
       "  'ok': True},\n",
       " {'config': '/Users/lucasmuller/Desktop/Githubg/Rawls_v3/hypothesis_testing/hypothesis_1/configs/hypothesis_1_condition_32_config.yaml',\n",
       "  'log': '/Users/lucasmuller/Desktop/Githubg/Rawls_v3/hypothesis_testing/hypothesis_1/terminal_outputs/hypothesis_1_condition_32_log',\n",
       "  'result': '/Users/lucasmuller/Desktop/Githubg/Rawls_v3/hypothesis_testing/hypothesis_1/results/hypothesis_1_condition_32_config_results.json',\n",
       "  'returncode': 0,\n",
       "  'ok': True}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Discover all config files\n",
    "configs = list_config_files(CONFIG_DIR)\n",
    "print(f'Found {len(configs)} configs')\n",
    "\n",
    "# Selection controls\n",
    "All_SELECT_INDICES = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, \n",
    "11, 12, 13, 14, 15, 16, 17, 18, 19, 20, \n",
    "21, 22, 23, 24, 25, 26, 27, 28, 29, 30, \n",
    "31, 32, 33]  # e.g., [1,2,3] for the first three\n",
    "SELECT_INDICES = [15,32]\n",
    "SELECT_NAMES = None    # e.g., ['condition_1', 'condition_33']\n",
    "CONCURRENCY = 2      # adjust parallel workers\n",
    "TIMEOUT_SECONDS = None # e.g., 900 for 15 minutes per run\n",
    "\n",
    "selected = select_configs(configs, include_indices=SELECT_INDICES, include_names=SELECT_NAMES)\n",
    "print(f'Selected {len(selected)} configs to run')\n",
    "\n",
    "run_results = run_configs_in_parallel(\n",
    "    selected,\n",
    "    concurrency=CONCURRENCY,\n",
    "    logs_dir=TERMINAL_OUTPUTS_DIR,\n",
    "    results_dir=RESULTS_DIR,\n",
    "    timeout_sec=TIMEOUT_SECONDS,\n",
    ")\n",
    "\n",
    "# Quick summary\n",
    "ok = sum(1 for r in run_results if r.get('ok'))\n",
    "print(f'Completed: {ok}/{len(run_results)} OK')\n",
    "run_results[:3]  # show a few"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2fa0d6",
   "metadata": {},
   "source": [
    "## 3. Analysis — Principles vs. Disagreements\n",
    "\n",
    "Counts how often runs ended in consensus for each principle vs. disagreement (no consensus)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3ecb730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category | Count\n",
      "---------|------\n",
      "maximizing_floor                       | 0\n",
      "maximizing_average                     | 1\n",
      "maximizing_average_floor_constraint    | 29\n",
      "maximizing_average_range_constraint    | 0\n",
      "disagreement                           | 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({'maximizing_average_floor_constraint': 29,\n",
       "         'disagreement': 3,\n",
       "         'maximizing_average': 1,\n",
       "         'maximizing_floor': 0,\n",
       "         'maximizing_average_range_constraint': 0})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CATEGORIES = [\n",
    "    'maximizing_floor',\n",
    "    'maximizing_average',\n",
    "    'maximizing_average_floor_constraint',\n",
    "    'maximizing_average_range_constraint',\n",
    "    'disagreement',\n",
    "]\n",
    "\n",
    "def categorize_result(result_path: Path) -> str:\n",
    "    try:\n",
    "        with open(result_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        gi = data.get('general_information', {})\n",
    "        consensus = gi.get('consensus_reached', False)\n",
    "        principle = gi.get('consensus_principle')\n",
    "        if consensus and principle in CATEGORIES:\n",
    "            return principle\n",
    "        return 'disagreement'\n",
    "    except Exception:\n",
    "        return 'disagreement'\n",
    "\n",
    "counts = Counter()\n",
    "result_files = sorted(RESULTS_DIR.glob('*_results.json'))\n",
    "for rp in result_files:\n",
    "    counts[categorize_result(rp)] += 1\n",
    "\n",
    "# Ensure all categories are present\n",
    "for cat in CATEGORIES:\n",
    "    counts.setdefault(cat, 0)\n",
    "\n",
    "# Display as a simple table\n",
    "print('Category | Count')\n",
    "print('---------|------')\n",
    "for cat in CATEGORIES:\n",
    "    print(f'{cat:38} | {counts[cat]}')\n",
    "\n",
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10578fd4",
   "metadata": {},
   "source": [
    "## 4. Statistical Tests — Fisher–Freeman–Halton and Cramér's V\n",
    "\n",
    "Compare aggregated Hypothesis 1 outcomes (AI) against human outcomes as a 5×2 contingency table.\n",
    "\n",
    "- Rows (categories): the four principles + disagreement.\n",
    "- Columns (groups): Human vs AI.\n",
    "- Fisher–Freeman–Halton exact test via R's `fisher.test()` when available; fallback to Chi-square otherwise.\n",
    "- Cramér's V with bias correction and bootstrap CI.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "413a5525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI counts by category: {'maximizing_floor': 0, 'maximizing_average': 1, 'maximizing_average_floor_constraint': 29, 'maximizing_average_range_constraint': 0, 'disagreement': 3}\n",
      "Human counts by category: {'maximizing_floor': 5, 'maximizing_average': 1, 'maximizing_average_floor_constraint': 23, 'maximizing_average_range_constraint': 2, 'disagreement': 7}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 5,  0],\n",
       "        [ 1,  1],\n",
       "        [23, 29],\n",
       "        [ 2,  0],\n",
       "        [ 7,  3]]),\n",
       " ['maximizing_floor',\n",
       "  'maximizing_average',\n",
       "  'maximizing_average_floor_constraint',\n",
       "  'maximizing_average_range_constraint',\n",
       "  'disagreement'],\n",
       " ['Human', 'AI'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 1) Aggregate AI outcomes across all runs into 5 categories\n",
    "ai_counts = [counts.get(cat, 0) for cat in CATEGORIES]\n",
    "print('AI counts by category:', dict(zip(CATEGORIES, ai_counts)))\n",
    "\n",
    "# 2) Specify Human counts (edit to match hypothesis_testing/hypothesis_1/image copy.png)\n",
    "# Defaults below use Frohlich & Oppenheimer published values as a placeholder.\n",
    "HUMAN_COUNTS = {\n",
    "    'maximizing_floor': 5,\n",
    "    'maximizing_average': 1,\n",
    "    'maximizing_average_floor_constraint': 23,\n",
    "    'maximizing_average_range_constraint': 2,\n",
    "    'disagreement': 7,\n",
    "}\n",
    "human_counts = [HUMAN_COUNTS.get(cat, 0) for cat in CATEGORIES]\n",
    "print('Human counts by category:', dict(zip(CATEGORIES, human_counts)))\n",
    "\n",
    "# 3) Build 5×2 contingency table (rows=categories, cols=[Human, AI])\n",
    "contingency = np.vstack([human_counts, ai_counts]).T  # shape (5, 2)\n",
    "contingency, CATEGORIES, ['Human','AI']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c73846b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fisher–Freeman–Halton exact test p-value: 0.033087\n"
     ]
    }
   ],
   "source": [
    "def fisher_freeman_halton_pvalue_r(contingency: np.ndarray) -> float | None:\n",
    "    \"\"\"Run Fisher-Freeman-Halton test via R's fisher.test if available.\n",
    "    Returns p-value or None if Rscript not found or fails.\n",
    "    \"\"\"\n",
    "    if shutil.which('Rscript') is None:\n",
    "        return None\n",
    "    r_matrix = ','.join(str(int(x)) for x in contingency.flatten(order='C'))\n",
    "    nrow = contingency.shape[0]\n",
    "    r_code = f\"\"\"\n",
    "m <- matrix(c({r_matrix}), nrow={nrow}, byrow=TRUE);\n",
    "f <- tryCatch(fisher.test(m), error=function(e) NA);\n",
    "if (is.list(f)) {{ cat(f$p.value) }} else {{ cat('NA') }}\n",
    "\"\"\"\n",
    "    import subprocess\n",
    "    try:\n",
    "        out = subprocess.check_output(['Rscript', '-e', r_code], stderr=subprocess.STDOUT, text=True)\n",
    "        out = out.strip()\n",
    "        return float(out) if out and out != 'NA' else None\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "p_ffh = fisher_freeman_halton_pvalue_r(contingency)\n",
    "\n",
    "print(f'Fisher–Freeman–Halton exact test p-value: {p_ffh:.6f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7bef027f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "\n",
    "def _prune_empty_rows_cols(contingency: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Drop all-zero rows and columns to avoid degenerate shapes and expected=0 cells.\n",
    "    Returns the original array if nothing needs pruning.\n",
    "    \"\"\"\n",
    "    contingency = np.asarray(contingency, dtype=float)\n",
    "    if contingency.ndim != 2:\n",
    "        raise ValueError(\"contingency must be a 2D array\")\n",
    "\n",
    "    row_mask = contingency.sum(axis=1) > 0\n",
    "    col_mask = contingency.sum(axis=0) > 0\n",
    "\n",
    "    if row_mask.all() and col_mask.all():\n",
    "        return contingency\n",
    "    pruned = contingency[row_mask][:, col_mask]\n",
    "    return pruned\n",
    "\n",
    "\n",
    "def cramers_v(contingency: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Standard Cramér's V using Pearson's chi-square with NO Yates correction.\n",
    "    Matches the definition used by Bergsma (2013) before bias correction.\n",
    "    \"\"\"\n",
    "    tab = _prune_empty_rows_cols(contingency)\n",
    "    n = tab.sum()\n",
    "    if n <= 0:\n",
    "        return 0.0\n",
    "\n",
    "    r, c = tab.shape\n",
    "    df_min = min(r - 1, c - 1)\n",
    "    if df_min <= 0:\n",
    "        return 0.0\n",
    "\n",
    "    chi2, _, _, _ = chi2_contingency(tab, correction=False)\n",
    "    return float(np.sqrt((chi2 / n) / df_min))\n",
    "\n",
    "\n",
    "def bias_corrected_cramers_v(contingency: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Bergsma (2013) bias-corrected Cramér's V.\n",
    "    - Subtracts finite-sample bias for phi^2 at independence.\n",
    "    - Adjusts effective dimensions so the corrected measure can still reach 1.\n",
    "    Formulas:\n",
    "      phi2_corr = max(0, chi2/n - ((r-1)(c-1))/(n-1))\n",
    "      r_corr = r - ((r-1)^2)/(n-1)\n",
    "      c_corr = c - ((c-1)^2)/(n-1)\n",
    "      V_tilde = sqrt(phi2_corr / min(r_corr-1, c_corr-1))\n",
    "    \"\"\"\n",
    "    tab = _prune_empty_rows_cols(contingency)\n",
    "    n = tab.sum()\n",
    "    if n <= 1:\n",
    "        return 0.0\n",
    "\n",
    "    r, c = tab.shape\n",
    "    if min(r - 1, c - 1) <= 0:\n",
    "        return 0.0\n",
    "\n",
    "    chi2, _, _, _ = chi2_contingency(tab, correction=False)\n",
    "    phi2 = chi2 / n\n",
    "    r1, c1 = r - 1, c - 1\n",
    "\n",
    "    # Bias correction at independence\n",
    "    phi2_corr = max(0.0, phi2 - (r1 * c1) / (n - 1))\n",
    "\n",
    "    # Adjusted table dimensions\n",
    "    r_corr = r - (r1 * r1) / (n - 1)\n",
    "    c_corr = c - (c1 * c1) / (n - 1)\n",
    "    denom = min(r_corr - 1.0, c_corr - 1.0)\n",
    "    if denom <= 0.0:\n",
    "        return 0.0\n",
    "\n",
    "    return float(np.sqrt(phi2_corr / denom))\n",
    "\n",
    "\n",
    "def bootstrap_cramers_v(\n",
    "    contingency: np.ndarray,\n",
    "    n_bootstrap: int = 5000,\n",
    "    confidence_level: float = 0.95,\n",
    "    bias_corrected: bool = True,\n",
    "    seed: int | None = 123,\n",
    ") -> tuple[np.ndarray, float, float]:\n",
    "    \"\"\"\n",
    "    Nonparametric bootstrap for Cramér's V by resampling counts from the empirical\n",
    "    cell distribution via Multinomial(n, p). Uses percentile CI.\n",
    "\n",
    "    Returns:\n",
    "        (vs, lo, hi)\n",
    "        - vs: array of bootstrap V values\n",
    "        - lo, hi: lower/upper bounds of the (1 - alpha) percentile CI\n",
    "    \"\"\"\n",
    "    tab = np.asarray(contingency, dtype=float)\n",
    "    n = int(tab.sum())\n",
    "    if n <= 0:\n",
    "        return np.array([]), 0.0, 0.0\n",
    "    if not (0.0 < confidence_level < 1.0):\n",
    "        raise ValueError(\"confidence_level must be in (0, 1)\")\n",
    "\n",
    "    p = (tab / n).ravel()\n",
    "    idxs = np.arange(p.size)\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "    vs = np.empty(n_bootstrap, dtype=float)\n",
    "\n",
    "    for b in range(n_bootstrap):\n",
    "        # Draw a bootstrap table ~ Multinomial(n, p)\n",
    "        counts = rng.multinomial(n, p).reshape(tab.shape)\n",
    "        v = bias_corrected_cramers_v(counts) if bias_corrected else cramers_v(counts)\n",
    "        vs[b] = v\n",
    "\n",
    "    alpha = 1.0 - confidence_level\n",
    "    lo, hi = np.quantile(vs, [alpha / 2.0, 1.0 - alpha / 2.0])\n",
    "    return vs, float(lo), float(hi)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30063653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias-corrected Cramér's V: 0.265347\n"
     ]
    }
   ],
   "source": [
    "cramers_v_value = bias_corrected_cramers_v(contingency)\n",
    "\n",
    "print(f'Bias-corrected Cramér\\'s V: {cramers_v_value:.6f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
