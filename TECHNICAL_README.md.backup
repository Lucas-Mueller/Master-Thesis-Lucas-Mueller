# TECHNICAL README: Frohlich Experiment Framework

## Executive Summary

This document provides a comprehensive technical analysis of the **Frohlich Experiment** framework—a sophisticated Python system for conducting computational experiments on distributive justice. The framework orchestrates AI agents in a two-phase experiment grounded in **Rawlsian philosophy** and inspired by economist Norman Frohlich's empirical work on justice principles.

**Core Thesis**: Under a computationally-simulated "veil of ignorance," agents autonomously reason about and reach consensus on principles of distributive justice through formal voting mechanisms and memory-augmented discussion.

**Scale**: ~10,452 lines of production code across 60+ modules implementing:
- Two-phase experiment orchestration with 6 specialized Phase 2 services
- Deterministic two-stage voting system with multilingual support
- Sophisticated memory management with content truncation
- Reproducible experiments via seeding and configuration
- Multi-provider LLM support (OpenAI, Google Gemini, OpenRouter, Ollama)

---

## 1. Core Experimental Model

### 1.1 The Veil of Ignorance Scenario

The experiment implements a computational variant of **John Rawls' veil of ignorance** thought experiment:

1. **Information Asymmetry**: Agents are randomly assigned to one of 5 income classes (high, medium_high, medium, medium_low, low)
2. **Uncertainty**: Agents know the 4 justice principles but not which class they'll occupy
3. **Deliberation**: Agents participate in structured discussion and reach consensus on a principle
4. **Payoff Realization**: After consensus, agents' actual income class is revealed, determining their final earnings

### 1.2 Four Justice Principles

The framework operationalizes four distinct principles (implemented in `models/principle_types.py`):

**Principle 1: MAXIMIZING_FLOOR**
- Strategy: Maximize the lowest income in the distribution
- Philosophy: Rawlsian "difference principle" that prioritizes the worst-off members
- Configuration: No constraint parameters required

**Principle 2: MAXIMIZING_AVERAGE**
- Strategy: Maximize average income across all classes
- Philosophy: Utilitarian approach focused on total welfare maximization
- Configuration: No constraint parameters required

**Principle 3: MAXIMIZING_AVERAGE_FLOOR_CONSTRAINT**
- Strategy: Maximize average income while maintaining a minimum floor constraint
- Example: Maximize average income but ensure no class earns less than fifteen thousand dollars
- Configuration: Requires a positive integer constraint amount specification

**Principle 4: MAXIMIZING_AVERAGE_RANGE_CONSTRAINT**
- Strategy: Maximize average income while limiting the income spread between highest and lowest earners
- Example: Maximize average income but ensure income spread does not exceed ten thousand dollars
- Configuration: Requires a positive integer constraint amount specification

Each principle produces different income distributions and payoffs for different agent classes, creating meaningful trade-offs in the bargaining process.

### 1.3 Income Distribution System

**Distribution Generator** (`core/distribution_generator.py`) provides four income distributions per round:

**Base Distribution Structure**: The system uses a standard baseline distribution with five income classes:
- High income (Class 1, richest): $32,000
- Medium-high income (Class 2): $27,000
- Medium income (Class 3, most likely): $24,000
- Medium-low income (Class 4): $13,000
- Low income (Class 5, poorest): $12,000

**Two distribution generation modes**:

1. **Dynamic Mode**: Applies random scaling multipliers (ranging from 0.8 to 1.2) to the base distribution. The multiplier is generated from a seeded random number generator for reproducibility. Each income class value is multiplied by this scaling factor to create varied economic scenarios.

2. **Original Values Mode**: Uses predefined historical distributions derived from Frohlich's original empirical data. The system maps rounds to specific situations: Round 1 uses Situation A, Round 2 uses Situation B, Round 3 uses Situation C, and Round 4 uses Situation D.

**Income Class Probabilities**: Each round specifies probability distributions for class assignment:
- High income: 5% probability
- Medium-high income: 10% probability
- Medium income: 50% probability (modal class - most likely)
- Medium-low income: 25% probability
- Low income: 10% probability

When calculating payoffs, the framework uses **weighted expected value** calculations by summing the products of each income class value multiplied by its probability.

---

## 2. Two-Phase Experiment Architecture

### 2.1 Phase 1: Individual Familiarization (Parallel Execution)

**Purpose**: Agents independently learn about justice principles and reason about their preferences without group influence.

**Flow** (`core/phase1_manager.py`):

The Phase 1 manager executes tasks for each participant in parallel using asynchronous task scheduling:

1. **Initial Ranking**: The agent ranks the four justice principles from 1 to 4 (best to worst) without any prior knowledge of specific income distributions

2. **Principle Explanation**: The agent receives detailed explanations of each principle, including empirical payoff examples that illustrate real outcomes

3. **Post-Explanation Ranking**: The agent re-ranks the principles after understanding their practical implications. This tests both learning effectiveness and preference stability

4. **Application Tasks** (four rounds): For each round, the agent receives four different income distributions, selects which distribution to apply their chosen principle to, and the system calculates the participant's expected payoff. The participant then provides reasoning for their choices

**Key Implementation Details**:

- **Deterministic Random Number Generators**: Each participant receives a seeded random number generator instance, where the seed equals the base experiment seed plus the agent's index (e.g., agent 0 gets seed 42, agent 1 gets seed 43, etc.). This ensures complete reproducibility across experiment runs.

- **Memory Management**: The system integrates a SelectiveMemoryManager for context truncation to prevent context window overflow. Old statements are truncated to a maximum of 300 characters each, and accumulated internal reasoning is limited to 200 characters.

- **Output Structure**: Phase1Results contains the agent's initial ranking, post-explanation ranking, application results from all four rounds, participant name, and completion status indicator.

### 2.2 Phase 2: Group Discussion and Consensus (Sequential with Services)

**Purpose**: Agents engage in structured group discussion to reach collective consensus on a justice principle via formal voting.

**Architecture**: Services-first design with 6 specialized services orchestrated by Phase2Manager:

The Phase2Manager acts as an orchestrator that delegates responsibilities to specialized services:
- **SpeakingOrderService**: Manages turn allocation with finisher restrictions
- **DiscussionService**: Generates discussion prompts and validates statements
- **VotingService**: Coordinates the complete voting process (initiation, confirmation, and ballot)
- **MemoryService**: Updates agent memories with event summaries
- **CounterfactualsService**: Calculates payoffs and prepares results formatting
- **ManipulatorService**: Provides optional experimental manipulation capabilities

**Full Phase 2 Flow**:

Phase 2 executes an asynchronous workflow that coordinates group discussion and formal consensus building:

**Initialization**: The speaking order service determines the turn allocation for each round, optionally applying finisher restrictions if that setting is active.

**Discussion Rounds Loop**: For each round (from 1 to the configured maximum):

**1. Discussion Stage** - Sequential agent statements with memory context:
- For each participant in the speaking order, the discussion service builds a contextual discussion prompt that incorporates the participant's Phase 1 results, the discussion history, current round number, and consensus status
- The agent generates a statement by processing the discussion prompt
- The statement is validated against minimum length requirements (with up to 3 retries if validation fails)
- The validated statement is appended to the public history with metadata (round number, participant name, timestamp)
- The memory service updates the agent's memory with a truncated summary (maximum 300 characters)

**2. Voting Initiation Check**:
- The discussion service builds a voting initiation prompt asking if agents want to initiate voting
- Each participant responds with a binary answer (1=Yes, 0=No) using numerical agreement detection
- If any participant votes yes, or if this is the final round, voting proceeds

**2a. Confirmation Phase** (if voting initiated):
- The voting service coordinates a confirmation phase where all agents must agree to participate
- Confirmation results indicate whether all agents confirmed (requires 100% agreement to proceed)

**2b. Secret Ballot** (if all confirmed):
- **Stage 1 - Principle Selection**: Each participant receives a ballot prompt and responds with a principle number (1-4). The TwoStageVotingManager extracts the principle number via regex (with up to 3 retries). If extraction fails, the system falls back to keyword matching in the participant's language
- **Stage 2 - Amount Specification**: For participants who voted for principles 3 or 4 (constraint principles), the system prompts for a constraint amount and extracts a positive integer via regex (with up to 3 retries)

**2c. Consensus Detection**:
- The voting service detects consensus by checking if all votes are identical in strict mode
- If consensus is reached, the system records the consensus principle and constraint amount, then exits the round loop
- If no consensus, the system updates voting failure memory and continues to the next discussion round

**3. Payoff Calculation and Results Formatting**:
- The counterfactuals service calculates final results based on whether consensus was reached and which principle was selected
- The service formats detailed results including participant payoffs

**4. Final Rankings Collection**:
- Each participant receives a final ranking prompt
- The utility agent parses the ranking responses
- Rankings are stored in the final results

**Return**: The system returns comprehensive Phase2Results containing consensus status, the final principle and constraint amount, the complete discussion transcript, per-participant results, and the number of rounds completed.

---

## 3. Service-Based Architecture (Phase 2 Core)

The framework employs a **services-first architecture** for Phase 2, replacing monolithic logic with focused, testable services using **Protocol-based dependency injection**.

### 3.1 SpeakingOrderService

**File**: `core/services/speaking_order_service.py`

**Responsibility**: Manage turn allocation with optional finisher restrictions.

**Key Methods**:

**determine_speaking_order** - Determines speaking order for each round with finisher restrictions:
- Takes a list of participant agents and an optional boolean flag to randomize the finisher
- Returns a dictionary mapping round numbers to ordered lists of participants
- Algorithm: Randomly shuffles participant order using a seeded random number generator. If randomize_finisher is enabled, ensures the last speaker differs from previous rounds. Returns the round-to-participants mapping
- Finisher Restriction philosophy: The agent speaking last must not have spoken last in any previous round, which encourages new perspectives at round conclusion

**apply_finisher_restrictions** - Reorders participant list to ensure a new finisher:
- Takes a proposed speaking order and a set of previous finisher names
- Returns a reordered list of participants
- Purpose: Enforces the finisher restriction by swapping participants if necessary

**Configuration**:

Phase 2 settings control finisher behavior:
- **finisher_restrictions_active**: Boolean flag to enable finisher reordering (true/false)
- **use_fixed_speaking_order**: Boolean flag to specify a fixed order instead of random (true/false)

### 3.2 DiscussionService

**File**: `core/services/discussion_service.py`

**Responsibility**: Generate contextual discussion prompts, validate statements, manage discussion history.

**Key Methods**:

**build_discussion_prompt** - Builds contextual discussion prompts:
- Takes the participant agent, their Phase 1 results, the discussion history, current round number, and consensus status
- Returns a localized prompt template with agent-specific context
- Includes: The agent's Phase 1 rankings and application results, a summary of previous statements (with truncation applied), current round context, and system instructions for tone and length

**validate_statement** - Validates statement quality:
- Takes a statement string, minimum length threshold (default 50 characters), and maximum retry count (default 3)
- Returns the validated statement string
- Process: Checks if the statement meets minimum length requirements and retries up to the maximum if validation fails
- Raises a ValidationError exception if maximum retries are exceeded

**manage_discussion_history_length** - Truncates discussion history intelligently:
- Takes the history list and maximum character length
- Returns the truncated history list
- Strategy: Removes oldest entries first (chronological ordering), keeps enough context for decision-making, and preserves critical principle discussion
- Uses the Phase2Settings public_history_max_length parameter (default: 100,000 characters)

**Multilingual Support**:

The service uses translation keys for discussion prompts:
- Round start prompts: "discussion_round_{round}_start"
- Voting initiation prompts: "discussion_voting_initiation"
- Final round prompts: "discussion_final_round"

The language manager retrieves localized versions for English, Spanish, and Mandarin by calling the get method with the translation key and any required parameters (such as round number).

### 3.3 VotingService

**File**: `core/services/voting_service.py`

**Responsibility**: Coordinate complete voting process (initiation → confirmation → secret ballot).

**Key Methods**:

**initiate_voting** - Determines if voting should be initiated:
- Takes participants list, discussion state, current round number, and optional timeout in seconds
- Returns a VotingInitiationResult containing whether voting should proceed and which participant initiated it
- Process: Generates an initiation prompt asking "Do you want to initiate voting?", collects responses from each participant with numerical answer detection (1=Yes, 0=No), and returns after the first Yes response or when all participants have been checked

**coordinate_voting_confirmation** - Confirmation Phase where all agents must agree:
- Takes participants list, discussion state, current round number, and optional timeout in seconds
- Returns a ConfirmationResult containing an all_confirmed boolean and a dictionary mapping participant names to vote-confidence tuples
- Process: Sends confirmation prompt "Do you agree to participate in voting? (1=Yes, 0=No)" to all participants, collects responses, and validates that 100% agreement was achieved (all agents said Yes)

**coordinate_secret_ballot** - Executes two-stage secret ballot process:
- Takes participants list, current round number, and optional timeout in seconds
- Returns a SecretBallotResult containing vote data
- Stages: Stage 1 collects principle selection (1-4), Stage 2 collects amount specification (for principles 3 and 4)
- Implementation: Handled by TwoStageVotingManager with deterministic numerical validation

**detect_consensus** - Detects unanimous agreement on principle and constraint:
- Takes a list of vote tuples (principle number, optional constraint amount) and a strict mode boolean flag
- Returns either a ConsensusResult object or None if no consensus reached
- Behavior: In strict mode (True), all agents must vote identically. In non-strict mode (False), majority rule applies (not used in current implementation)

**Error Handling**:

The service implements automatic retry with exponential backoff through an internal method that executes voting interactions with timeout protection. When a timeout occurs, the system retries up to the configured voting_retry_limit with exponentially increasing timeout durations (using an asyncio.wait_for pattern with timeout escalation).

### 3.4 TwoStageVotingManager

**File**: `core/two_stage_voting_manager.py`

**Responsibility**: Deterministic two-stage voting with multilingual validation.

**Stage 1: Principle Selection** (Deterministic Numerical Input)

**conduct_principle_selection** - Executes Stage 1 principle selection:
- Takes participants list, round number, and optional timeout in seconds
- Returns a dictionary mapping participant names to principle numbers (1-4)
- Algorithm:
  1. Sends prompt: "Which principle do you choose? (1=Floor, 2=Average, 3=Avg+Floor, 4=Avg+Range)"
  2. For each participant: Gets response, uses regex to extract first digit 1-4, falls back to keyword matching in participant's language on parse failure, retries up to max_retries on continued failure
- Key Design: Replaces complex LLM-based principle detection with regex validation, supports keyword fallback for multilingual responses, and provides deterministic results with no interpretation variance

**Internal extraction method**: Extracts the first digit 1-4 from response text using regular expression pattern matching, returning the integer value if found or None if not found

**Stage 2: Amount Specification** (For Constraint Principles)

**conduct_amount_specification** - Executes Stage 2 amount specification:
- Takes participants list, principle mapping from Stage 1, round number, and optional timeout
- Returns a dictionary mapping participant names to constraint amounts (or None)
- Algorithm:
  1. Filters participants who voted for principle 3 or 4
  2. For each filtered participant: Sends prompt "What is your constraint amount? Please specify a number.", uses regex to extract first positive integer, retries with cultural adaptation (number format parsing) on parse failure, returns integer or None if failed after retries
- Multilingual Number Parsing Support:
  - English: Handles 1000, 1,000 (comma separator), 1.000 (period separator)
  - Spanish: Handles 1.000 (period for thousands), 1,000 (comma)
  - Mandarin: Handles 1000 with cultural context for large numbers
- Uses the get_amount_formatter function from the cultural_adaptation module

**Internal extraction method**: Extracts the first positive integer from response text using regular expression pattern matching, returning the integer value if found or None otherwise

**Key Design Rationale**:
- **Deterministic**: Replaces complex LLM parsing approaches (such as "Does the agent want principle 3?") with simple regex pattern matching
- **Multilingual**: Supports keyword fallback and cultural number formatting for international use
- **Auditable**: Each vote is extractable from the raw response with clear validation rules
- **Testable**: Uses stateless validation functions that enable comprehensive unit testing

### 3.5 MemoryService

**File**: `core/services/memory_service.py`

**Responsibility**: Unified memory management with intelligent routing and content truncation.

**Architecture**:

```
SelectiveMemoryManager (lower-level)
    ↓ (wrapped by)
MemoryService (public API)
    ├── Routes events by type (discussion, voting, results)
    ├── Applies truncation rules (≤300 char statements, ≤200 char reasoning)
    ├── Delegates to SelectiveMemoryManager for implementation
    └── Provides consistent guidance style application
```

**Key Methods**:

```python
async def update_discussion_memory(
    self,
    agent: ParticipantAgent,
    context: ParticipantContext,
    statement_summary: str,  # Participant's statement
    round_number: int,
    include_reasoning: bool = False
) -> str:
    """
    Update agent memory with discussion statement.

    Process:
    1. Truncate statement to 300 characters
    2. Format with memory guidance style (narrative or structured)
    3. Delegate to SelectiveMemoryManager for insertion
    4. Return memory update result

    Routing: Routes to update_memory_simple() for direct insertion
    """

async def update_voting_memory(
    self,
    agent: ParticipantAgent,
    context: ParticipantContext,
    event_type: MemoryEventType,  # VOTING_INITIATED, VOTING_CONFIRMED, BALLOT_COMPLETED
    round_number: int,
    vote_choice: Optional[PrincipleChoice] = None,
    consensus_reached: bool = False
) -> str:
    """
    Update agent memory with voting event.

    Three sub-events:
    1. VOTING_INITIATED: Group is considering voting
    2. VOTING_CONFIRMED: All agents agreed to participate
    3. BALLOT_COMPLETED: Secret ballot results (with consensus if reached)

    Routing: Routes to update_memory_complex() if consensus reached,
             simple insertion if just status update
    """

async def update_final_results_memory(
    self,
    agent: ParticipantAgent,
    context: ParticipantContext,
    result_content: str,
    final_earnings: float,
    consensus_reached: bool
) -> str:
    """
    Update agent memory with final Phase 2 results.

    Content:
    - Consensus principle and constraint (if reached)
    - Agent's assigned income class
    - Final earnings (actual payoff)
    - Counterfactual earnings under other principles

    Routing: Always uses update_memory_complex() for detailed analysis
    """

def _truncate_content(
    self,
    content: str,
    content_type: str  # 'statement', 'reasoning', 'result'
) -> str:
    """
    Apply truncation rules based on Phase2Settings:
    - statement: ≤ 300 characters
    - reasoning: ≤ 200 characters
    - result: No truncation (full results preserved)
    """

def _apply_guidance_style(
    self,
    content: str,
    guidance_style: str  # 'narrative' or 'structured'
) -> str:
    """
    Format memory content with guidance style:

    narrative: "Agent Alice discussed the importance of fairness..."
    structured: "Topic: Fairness; Agent: Alice; Key Points: ..."
    """
```

**Configuration**:
```yaml
phase2_settings:
  memory_management:
    guidance_style: "narrative"  # or "structured"
    public_history_max_length: 100000  # characters
    statement_max_length: 300
    reasoning_max_length: 200
    enable_truncation: true
```

### 3.6 CounterfactualsService

**File**: `core/services/counterfactuals_service.py`

**Responsibility**: Calculate payoffs, generate counterfactual analyses, format detailed results.

**Payoff Calculation Algorithm**:

```python
async def calculate_payoffs(
    self,
    distribution_set: DistributionSet,
    consensus_principle: Optional[JusticePrinciple],
    participants: List[ParticipantAgent],
    income_probabilities: IncomeClassProbabilities
) -> Dict[str, float]:  # participant_name -> final_earnings
    """
    Calculate final payoffs based on consensus principle.

    Two scenarios:

    SCENARIO 1: Consensus Reached
        Apply the consensus principle to the distribution
        principle_mapping = apply_principle(consensus_principle, distribution)

        For each participant:
            1. Randomly assign income class using seeded RNG (respects probabilities)
            2. Look up income for assigned class in mapped distribution
            3. earnings[participant] = income

    SCENARIO 2: No Consensus
        Assign principle randomly from 4 principles
        random_principle = random.choice([Principle1, Principle2, Principle3, Principle4])

        Then apply same process as Scenario 1

    Returns: Dict mapping participant names to final earnings
    """

def _apply_principle_to_distribution(
    self,
    principle: JusticePrinciple,
    original_distribution: IncomeDistribution,
    constraint_amount: Optional[int] = None
) -> Dict[IncomeClass, int]:
    """
    Apply principle to original distribution, return optimized mapping.

    Principle 1: MAXIMIZING_FLOOR
        Objective: Maximize lowest income
        Algorithm: For each income class, optimize to maximize floor()
        Result: Modified distribution where floor is highest possible

    Principle 2: MAXIMIZING_AVERAGE
        Objective: Maximize average income
        Algorithm: Scale entire distribution uniformly (already optimal)
        Result: Original distribution (no change needed)

    Principle 3: MAXIMIZING_AVERAGE_FLOOR_CONSTRAINT
        Objective: Maximize average with floor constraint
        Algorithm:
            1. Set all incomes ≥ constraint_amount
            2. Remaining budget → maximize average

        Example:
            Original: high=32k, med=24k, med_low=13k, low=12k, avg=20.2k
            Constraint: 15k floor
            Result: high=38k, med=30k, med_low=15k, low=15k, avg=21.6k
                    (redistributed to satisfy floor while maximizing avg)

    Principle 4: MAXIMIZING_AVERAGE_RANGE_CONSTRAINT
        Objective: Maximize average with range constraint
        Algorithm:
            1. Calculate range: high - low ≤ constraint_amount
            2. Maximize average subject to range constraint

        Example:
            Original: high=32k, low=12k, range=20k, avg=20.2k
            Constraint: 10k range max
            Result: high=22k, low=12k, range=10k, avg=17.2k
                    (compressed to satisfy range limit)
    """

async def format_detailed_results(
    self,
    participants: List[ParticipantAgent],
    final_payoffs: Dict[str, float],
    consensus_reached: bool,
    consensus_principle: Optional[JusticePrinciple],
    distribution_set: DistributionSet
) -> Dict[str, DetailedResult]:
    """
    Generate transparent results showing:

    For each participant:
        1. Final principle (consensus or random)
        2. Assigned income class
        3. Final earnings
        4. COUNTERFACTUAL earnings under each of 4 principles
            (with same income class assignment)
        5. Counterfactual earnings under each of 4 distributions
            (with same principle assignment)

    Returns: Dict[participant_name -> {
        assigned_income_class: IncomeClass,
        final_earnings: float,
        counterfactual_by_principle: Dict[principle -> earnings],
        counterfactual_by_distribution: Dict[distribution_idx -> earnings]
    }]

    Purpose: Transparency and post-hoc analysis
    "Here's what you earned. Here's what you would have earned under other principles."
    """

async def collect_final_rankings(
    self,
    participants: List[ParticipantAgent],
    results: Dict[str, DetailedResult]
) -> Dict[str, PrincipleRanking]:
    """
    Ask participants to re-rank principles after seeing results.

    Process:
    1. Generate final ranking prompt with counterfactual results
    2. Each participant ranks 4 principles 1-4 (best to worst)
    3. Parse ranking using utility_agent.parse_principle_ranking()
    4. Validate ranking completeness

    Returns: Dict[participant_name -> PrincipleRanking]

    Purpose: Measure shift in preferences after payoff revelation
    """
```

**Counterfactual Generation Example**:

```
Participant: Alice
Final Principle: MAXIMIZING_FLOOR (voted unanimously)
Distribution Set Round 4:
  - Dist 1: high=32k, med=24k, low=12k
  - Dist 2: high=28k, med=20k, low=13k
  - Dist 3: high=31k, med=21k, low=14k
  - Dist 4: high=21k, med=19k, low=15k

Alice's Assigned Income Class: medium (50% probability)

ACTUAL RESULT:
  Distribution Used: Dist 1 (application-chosen)
  Principle Used: MAXIMIZING_FLOOR
  Alice's Earnings: 24000

COUNTERFACTUALS (same income class):

By Principle (Dist 1):
  If Maximizing_Floor → 24000 (actual)
  If Maximizing_Average → 24000 (different mapping, potentially different income)
  If Avg+Floor(15k) → 25000
  If Avg+Range(10k) → 23000

By Distribution (Maximizing_Floor principle):
  If Dist 1 → 24000 (actual)
  If Dist 2 → 20000 (lower incomes)
  If Dist 3 → 21000
  If Dist 4 → 19000
```

---

## 4. Voting System: Deep Dive

### 4.1 Voting Architecture

The voting system orchestrates three phases:

```
VOTING FLOW:
├── Phase 1: VOTING INITIATION
│   └── Any agent can trigger: "Do you want to initiate voting?" (1=Yes/0=No)
│
├── Phase 2: VOTING CONFIRMATION
│   └── All must agree: "Do you confirm to participate in voting?" (1=Yes/0=No)
│       Requires 100% unanimous agreement
│
└── Phase 3: SECRET BALLOT (TwoStageVotingManager)
    ├── Stage 1: Principle Selection (1-4)
    │   └── Extract numerical response: "Which principle? (1/2/3/4)"
    │
    └── Stage 2: Amount Specification (principles 3 & 4)
        └── Extract amount: "What is your constraint? (positive integer)"
```

### 4.2 Consensus Definition

**Strict Unanimity**: All participants must vote:
- **Same principle** (1, 2, 3, or 4)
- **Same constraint amount** (if principle 3 or 4)

```python
def detect_consensus(votes: List[Tuple[int, Optional[int]]]) -> bool:
    """
    Example:
    votes = [
        (1, None),  # Alice: Floor, no constraint
        (1, None),  # Bob: Floor, no constraint
        (1, None),  # Carol: Floor, no constraint
    ]
    → consensus = True (all agree on principle 1)

    votes = [
        (3, 15000),  # Alice: Avg+Floor, floor=15k
        (3, 15000),  # Bob: Avg+Floor, floor=15k
        (3, 15000),  # Carol: Avg+Floor, floor=15k
    ]
    → consensus = True (all agree on principle 3 with 15k floor)

    votes = [
        (1, None),   # Alice: Floor
        (2, None),   # Bob: Average ← Different!
        (1, None),   # Carol: Floor
    ]
    → consensus = False (no unanimous agreement)
    """
    if not votes:
        return False

    first_vote = votes[0]
    return all(vote == first_vote for vote in votes)
```

### 4.3 Timeout and Retry Mechanisms

**Configuration**:
```yaml
phase2_settings:
  voting_initiation_timeout: 30  # seconds
  voting_confirmation_timeout: 30
  voting_secret_ballot_timeout: 45
  voting_retry_limit: 3
  voting_retry_backoff_factor: 1.5  # exponential backoff
```

**Retry Algorithm**:
```python
async def _invoke_with_retry(
    prompt: str,
    max_retries: int = 3,
    base_timeout: float = 30
) -> str:
    """
    Execute with exponential backoff retry:

    Attempt 1: timeout = 30s
    Attempt 2: timeout = 45s (30 × 1.5)
    Attempt 3: timeout = 67.5s (45 × 1.5)

    Stops on:
    - Successful response
    - Max retries exceeded
    """
    for attempt in range(max_retries):
        timeout = base_timeout * (1.5 ** attempt)
        try:
            return await asyncio.wait_for(
                participant.think(prompt),
                timeout=timeout
            )
        except asyncio.TimeoutError:
            if attempt < max_retries - 1:
                await asyncio.sleep(1)  # Brief pause before retry
            else:
                raise
```

---

## 5. Configuration System

### 5.1 YAML-Driven Configuration

**File**: `config/models.py` with Pydantic validation

**Structure**:
```yaml
# Main experiment config
experiment_name: "baseline_v1"
phase2_rounds: 10
distribution_mode: "dynamic"  # or "original_values"

# Phase 2 settings
phase2_settings:
  finisher_restrictions_active: true
  statement_min_length: 50
  statement_validation_retries: 3
  public_history_max_length: 100000

  memory_management:
    guidance_style: "narrative"  # or "structured"
    enable_truncation: true

  voting:
    voting_confirmation_timeout: 30
    voting_secret_ballot_timeout: 45
    voting_retry_limit: 3

# Agents (8 participants for standard setup)
agents:
  - name: "Alice"
    model: "gpt-4o"
    language: "en"
    temperature: 0.7

  - name: "Bob"
    model: "gpt-4o"
    language: "en"
    temperature: 0.7

  # ... 6 more agents

# Income distribution
income_class_probabilities:
  high: 0.05
  medium_high: 0.10
  medium: 0.50
  medium_low: 0.25
  low: 0.10

# Reproducibility
seed: 42  # Global seed for all RNGs
```

### 5.2 Multi-Provider Model Support

**Intelligent Model Provider Detection**:

```python
# In experiment_agents/participant_agent.py
class ModelProvider(Enum):
    OPENAI = "openai"
    GEMINI = "gemini"
    OPENROUTER = "openrouter"
    OLLAMA = "ollama"

def detect_model_provider(model_str: str) -> ModelProvider:
    """
    Auto-detect provider from model string:

    - "gpt-4o" → OpenAI
    - "o1-mini" → OpenAI
    - "gemini-2.0-flash" → Google Gemini
    - "provider/model" → OpenRouter (e.g., "anthropic/claude-3.5-sonnet")
    - "ollama/gemma2:7b" → Ollama
    """
```

**Provider-Specific Implementation**:
```python
if provider == ModelProvider.OPENAI:
    # Native OpenAI Agents SDK
    client = Agents(api_key=os.getenv("OPENAI_API_KEY"))

elif provider == ModelProvider.GEMINI:
    # Google Gemini (if GEMINI_API_KEY set)
    client = anthropic.Anthropic(
        api_key=os.getenv("GEMINI_API_KEY"),
        base_url="https://generativelanguage.googleapis.com/openai/"
    )

elif provider == ModelProvider.OPENROUTER:
    # OpenRouter proxy (any model via provider/model format)
    client = anthropic.Anthropic(
        api_key=os.getenv("OPENROUTER_API_KEY"),
        base_url="https://openrouter.ai/api/v1"
    )

elif provider == ModelProvider.OLLAMA:
    # Local Ollama instance
    client = anthropic.Anthropic(
        api_key=os.getenv("OLLAMA_API_KEY", "ollama"),
        base_url=os.getenv("OLLAMA_BASE_URL", "http://localhost:11434/v1")
    )
```

---

## 6. Multilingual Support

### 6.1 Translation Architecture

**File**: `utils/language_manager.py`

```python
class SupportedLanguage(Enum):
    ENGLISH = "en"
    SPANISH = "es"
    MANDARIN = "zh"

class LanguageManager:
    """
    Centralized translation management.

    Loads translations from JSON files:
    - translations/en.json
    - translations/es.json
    - translations/zh.json
    """

    def get(self, key: str, **kwargs) -> str:
        """
        Retrieve localized string with substitutions.

        Example:
            message = lang_manager.get(
                "discussion_round_X_start",
                round=3,
                agent_name="Alice"
            )
            # Returns: "Round 3: Alice, please share your thoughts..."
        """
```

### 6.2 Multilingual Voting

**Number Format Parsing** (`utils/cultural_adaptation.py`):

```python
def get_amount_formatter(language: SupportedLanguage):
    """
    Multilingual number format parsing:

    English:
        "1000", "1,000" → 1000

    Spanish:
        "1.000" (period=thousands), "1,000" (comma) → 1000

    Mandarin:
        "1000", "1千" (thousand), "1万" (ten thousand) → culturally aware
    """
```

**Keyword Fallback** (`core/principle_keywords.py`):

```python
def match_principle_from_text(text: str, language: SupportedLanguage) -> Optional[int]:
    """
    Fallback principle detection via keywords when numerical extraction fails.

    Example responses:

    English:
        "I choose the maximizing average principle" → 2
        "Floor constraint sounds best" → 3

    Spanish:
        "Prefiero maximizar el piso" → 1
        "El promedio me parece bien" → 2

    Mandarin:
        "最大化平均收入" → 2
        "保证最低收入" → 1
    """
```

---

## 7. Memory Management Deep Dive

### 7.1 Three-Tier Memory System

```
TIER 1: CONTEXT WINDOW (ParticipantAgent.context)
├── Current memories (truncated to fit context)
├── Updated by MemoryService after each event
└── Sent to LLM in every prompt

TIER 2: AGENT MEMORY STORAGE (MemoryManager)
├── Persistent memory across rounds
├── Accumulated discussion statements
├── Voting events and results
└── Truncated intelligently to prevent overflow

TIER 3: DISCUSSION HISTORY (GroupDiscussionState.public_history)
├── Shared among all agents
├── All statements (truncated versions)
└── Used for context window building
```

### 7.2 Truncation Rules

**Applied by MemoryService**:

```python
TRUNCATION_RULES = {
    "statement": {
        "max_chars": 300,
        "strategy": "truncate_end_with_ellipsis"
    },
    "reasoning": {
        "max_chars": 200,
        "strategy": "truncate_end_with_ellipsis"
    },
    "result": {
        "max_chars": None,  # No truncation
        "strategy": "preserve_full"
    }
}

# Example:
original_statement = "I believe in maximizing the floor because fairness requires we protect the worst-off members of society..."
truncated = original_statement[:300] + "..."
# Result: "I believe in maximizing the floor because fairness requires we protect the worst-off members of society..."
```

**History Truncation**:

```python
def manage_discussion_history_length(
    self,
    history: List[Dict],
    max_length_chars: int = 100000
) -> List[Dict]:
    """
    If total history exceeds max_length_chars:
    1. Remove oldest statement first
    2. Recalculate total length
    3. Repeat until under limit

    Ensures recent context preserved while old statements pruned.
    """
```

### 7.3 Selective Memory Manager

**File**: `utils/selective_memory_manager.py`

**Two Update Strategies**:

```python
async def update_memory_simple(
    agent: ParticipantAgent,
    context: ParticipantContext,
    summary: str
) -> str:
    """
    Direct Memory Insertion (fast, ~1 second):

    Directly append summary to agent.context.memory
    No LLM involvement
    Used for: Discussion statements, status updates
    """

async def update_memory_complex(
    agent: ParticipantAgent,
    context: ParticipantContext,
    new_information: str,
    internal_reasoning: str = ""
) -> str:
    """
    LLM-Mediated Memory Integration (slow, ~10 seconds):

    Ask agent's LLM to integrate new information:
    "Here's what happened: {new_information}
    Current memory: {existing_memory}

    Integrate the new information into memory, updating beliefs..."

    Returns: Agent's synthesized memory update
    Used for: Complex results, voting outcomes with reasoning
    """

# Routing in MemoryService:
if event_type in [VOTING_INITIATED, DISCUSSION_STATEMENT]:
    await selective_memory_manager.update_memory_simple(...)
elif event_type in [VOTING_COMPLETE, FINAL_RESULTS]:
    await selective_memory_manager.update_memory_complex(...)
```

---

## 8. Reproducibility and Seeding

### 8.1 Seed Management

**File**: `utils/seed_manager.py`

```python
class SeedManager:
    """
    Centralized seeding for reproducible experiments.

    Three levels of seeding:
    """

    def __init__(self, global_seed: int = 42):
        self.global_seed = global_seed
        self.random = random.Random(global_seed)  # Global RNG
        self.seeds_by_component = {}  # Per-component seeds

    def get_seed_for(self, component_name: str) -> int:
        """
        Get deterministic seed for a component:

        Example:
            phase1_seed = seed_manager.get_seed_for("phase1")
            participant_1_seed = seed_manager.get_seed_for("participant_1")
            voting_seed = seed_manager.get_seed_for("voting")

        Deterministic: Same global_seed → Same component seeds
        """

    def _build_participant_rngs(self, config: ExperimentConfiguration):
        """
        Create deterministic RNG for each participant:

        for i, agent in enumerate(agents):
            seed = global_seed + i  # e.g., 42, 43, 44, 45...
            agent_rng = random.Random(seed)

        Result: Each participant's randomization is independent but seeded
        """
```

### 8.2 Reproducibility Guarantees

**With configuration + seed, experiment is fully reproducible**:

```python
# Run 1
config = ExperimentConfiguration.from_yaml("config.yaml")
config.seed = 42
results_1 = await FrohlichExperimentManager(config).run_complete_experiment()

# Run 2 (identical to Run 1)
config = ExperimentConfiguration.from_yaml("config.yaml")
config.seed = 42
results_2 = await FrohlichExperimentManager(config).run_complete_experiment()

# results_1 == results_2 (exactly, not probabilistically)
# Same distributions, same agent decisions, same payoffs, same consensus
```

**What's Seeded**:
- Distribution generation (multiplier)
- Participant income class assignment
- Speaking order randomization
- Finisher restriction randomization

**What's NOT Seeded** (LLM-dependent):
- Agent reasoning and statement generation (stochastic by nature)
- Agent's voting choices (depends on LLM temperature and model state)

---

## 9. Data Model Reference

### 9.1 Core Type Hierarchy

```python
# Justice principles (models/principle_types.py)
class JusticePrinciple(str, Enum):
    MAXIMIZING_FLOOR = "maximizing_floor"  # Principle 1
    MAXIMIZING_AVERAGE = "maximizing_average"  # Principle 2
    MAXIMIZING_AVERAGE_FLOOR_CONSTRAINT = "maximizing_average_floor_constraint"  # Principle 3
    MAXIMIZING_AVERAGE_RANGE_CONSTRAINT = "maximizing_average_range_constraint"  # Principle 4

class PrincipleChoice(BaseModel):
    principle: JusticePrinciple
    constraint_amount: Optional[int] = None  # For principles 3 & 4
    certainty: CertaintyLevel  # VERY_UNSURE, UNSURE, NO_OPINION, SURE, VERY_SURE
    reasoning: Optional[str] = None

class PrincipleRanking(BaseModel):
    rankings: List[RankedPrinciple]  # 4 items, ranks 1-4
    certainty: CertaintyLevel

# Income distribution
class IncomeClass(str, Enum):
    HIGH = "high"
    MEDIUM_HIGH = "medium_high"
    MEDIUM = "medium"
    MEDIUM_LOW = "medium_low"
    LOW = "low"

class IncomeDistribution(BaseModel):
    high: int
    medium_high: int
    medium: int
    medium_low: int
    low: int

    # Methods:
    # - get_floor_income() → int
    # - get_average_income(probabilities) → float
    # - get_range() → int

class DistributionSet(BaseModel):
    distributions: List[IncomeDistribution]  # Always 4
    multiplier: float  # Applied to base

# Results
class Phase1Results(BaseModel):
    participant_name: str
    initial_ranking: PrincipleRanking
    post_explanation_ranking: PrincipleRanking
    application_results: List[ApplicationResult]  # 4 rounds
    completion_status: str

class Phase2Results(BaseModel):
    consensus_reached: bool
    final_principle: Optional[JusticePrinciple]
    final_constraint_amount: Optional[int]
    discussion_transcript: List[Dict]
    participant_results: Dict[str, DetailedResult]
    rounds_completed: int

class ExperimentResults(BaseModel):
    phase1_results: List[Phase1Results]
    phase2_results: Phase2Results
    metadata: Dict[str, Any]  # timestamps, seed, config file path, etc.
```

### 9.2 Context Objects

```python
class ParticipantContext(BaseModel):
    """
    Agent's working context updated throughout experiment.
    Sent in every prompt to the LLM.
    """
    participant_name: str
    current_phase: ExperimentPhase
    current_stage: ExperimentStage
    current_round: int
    memory: str  # Accumulated memory from MemoryService
    assigned_income_class: Optional[IncomeClass] = None
    interaction_type: Optional[str] = None  # "discussion", "voting", "ranking"

    # Phase 1 specific
    income_distributions: Optional[DistributionSet] = None
    principle_explanations: Optional[Dict] = None

    # Phase 2 specific
    public_discussion_history: Optional[str] = None
    current_principle_choice: Optional[PrincipleChoice] = None

class GroupDiscussionState(BaseModel):
    """
    Shared state for Phase 2 discussion.
    """
    public_history: List[Dict]  # All statements so far
    consensus_reached: bool
    consensus_principle: Optional[JusticePrinciple] = None
    consensus_constraint: Optional[int] = None
    current_round: int
    voting_in_progress: bool
```

---

## 10. Error Handling and Recovery

### 10.1 Error Type Hierarchy

**File**: `utils/error_handling.py`

```python
class ExperimentError(Exception):
    """Base for all experiment errors."""
    pass

class ExperimentLogicError(ExperimentError):
    """Logic errors in experiment flow."""
    pass

class AgentCommunicationError(ExperimentError):
    """Communication failures with agents."""
    pass

class ValidationError(ExperimentError):
    """Data validation errors."""
    pass

# Error handler with automatic retry
class ExperimentErrorHandler:
    async def handle_with_retry(
        self,
        coroutine,
        max_retries: int = 3,
        base_delay: float = 1.0
    ):
        """Execute with exponential backoff retry."""
```

### 10.2 Parsing Error Recovery

**File**: `utils/parsing_errors.py`

```python
class ParsingError(Enum):
    """Classification of parsing failures."""
    EXTRACTION_FAILED = "extraction_failed"  # Regex found nothing
    INVALID_FORMAT = "invalid_format"  # Found text but wrong format
    OUT_OF_RANGE = "out_of_range"  # Value outside expected range
    LANGUAGE_MISMATCH = "language_mismatch"  # Language doesn't match expected

def detect_parsing_failure_type(response: str, context: str) -> ParsingError:
    """Classify why parsing failed."""

def handle_parsing_error(error: ParsingError, response: str):
    """Route to appropriate recovery strategy."""
```

---

## 11. Experiment Flow Diagram

```
START: FrohlichExperimentManager
│
├─→ Load Configuration (ExperimentConfiguration.from_yaml)
│   └─→ Validate with Pydantic models
│
├─→ Create Agents
│   ├─→ 8 ParticipantAgents (with model provider detection)
│   └─→ 1 UtilityAgent (for parsing)
│
├─→ PHASE 1 EXECUTION (Parallel)
│   │
│   └─→ For each participant (asyncio.create_task):
│       ├─→ Initial Ranking (rank 4 principles)
│       ├─→ Principle Explanation (receive explanation)
│       ├─→ Post-Explanation Ranking (re-rank)
│       └─→ Application Tasks (4 rounds):
│           ├─→ Generate distribution set
│           ├─→ Agent selects distribution
│           ├─→ Calculate payoff
│           └─→ Update memory
│
├─→ PHASE 2 EXECUTION (Sequential)
│   │
│   ├─→ Initialize Services
│   │   ├─→ SpeakingOrderService
│   │   ├─→ DiscussionService
│   │   ├─→ VotingService
│   │   ├─→ MemoryService
│   │   ├─→ CounterfactualsService
│   │   └─→ ManipulatorService (optional)
│   │
│   ├─→ For each round (1 to phase2_rounds):
│   │   │
│   │   ├─→ Determine Speaking Order
│   │   │
│   │   ├─→ DISCUSSION STAGE:
│   │   │   └─→ For each speaker:
│   │   │       ├─→ Build discussion prompt
│   │   │       ├─→ Agent generates statement
│   │   │       ├─→ Validate (length check, retries)
│   │   │       ├─→ Update public history
│   │   │       └─→ Update agent memories
│   │   │
│   │   ├─→ VOTING CHECK:
│   │   │   ├─→ Any agent initiate voting? (1=Yes/0=No)
│   │   │   └─→ Is final round?
│   │   │
│   │   └─→ IF VOTING INITIATED OR FINAL ROUND:
│   │       │
│   │       ├─→ VOTING CONFIRMATION PHASE:
│   │       │   └─→ All agents confirm participation (1=Yes/0=No)
│   │       │       Requires 100% agreement
│   │       │
│   │       ├─→ IF ALL CONFIRMED:
│   │       │   │
│   │       │   ├─→ STAGE 1: Principle Selection (TwoStageVotingManager)
│   │       │   │   └─→ Extract principle number 1-4 via regex
│   │       │   │       (with keyword fallback)
│   │       │   │
│   │       │   ├─→ STAGE 2: Amount Specification (if principle 3 or 4)
│   │       │   │   └─→ Extract constraint amount via regex
│   │       │   │       (with cultural adaptation for number formats)
│   │       │   │
│   │       │   └─→ DETECT CONSENSUS:
│   │       │       └─→ All votes identical?
│   │       │           ├─→ YES: Set consensus_reached=True, exit rounds
│   │       │           └─→ NO: Update voting failure memory, continue
│   │       │
│   │       └─→ IF NOT ALL CONFIRMED:
│   │           └─→ Update confirmation failure memory, continue
│   │
│   └─→ [End of round loop - either consensus reached or max rounds]
│
├─→ PAYOFF CALCULATION (CounterfactualsService)
│   │
│   ├─→ Apply consensus principle (or random if no consensus)
│   ├─→ Randomly assign income classes (seeded, respects probabilities)
│   ├─→ Calculate final earnings for each agent
│   └─→ Calculate counterfactuals (earnings under all 4 principles)
│
├─→ FINAL RANKING COLLECTION
│   │
│   └─→ For each agent:
│       ├─→ Present results with counterfactuals
│       ├─→ Ask to re-rank principles
│       └─→ Parse ranking
│
└─→ COMPILE RESULTS & EXPORT
    ├─→ ExperimentResults (phase1 + phase2 + metadata)
    └─→ Save to JSON

END
```

---

## 12. Performance Characteristics

### 12.1 Phase 1 Timing

- **Per participant**: ~30-60 seconds
- **Total (8 participants parallel)**: ~60 seconds
- **Breakdown**:
  - Initial ranking: 5-10 seconds
  - Explanations: 10-15 seconds
  - 4 application rounds: 15-30 seconds
  - Memory updates: 5-10 seconds

### 12.2 Phase 2 Timing

- **Per round**: 2-4 minutes (depends on agent count)
- **Typical experiment** (10 rounds): 20-40 minutes
- **Breakdown per round**:
  - Discussion (8 agents × 20-30s each): 2-4 minutes
  - Voting check: 30 seconds
  - If voting initiated:
    - Confirmation phase: 1-2 minutes
    - Secret ballot (stage 1 + 2): 2-3 minutes
    - Consensus detection: instant

### 12.3 Token Usage (GPT-4o)

- **Phase 1**: ~50,000 tokens (8 agents)
- **Phase 2 (10 rounds)**: ~200,000 tokens
- **Total per experiment**: ~250,000 tokens (~$10-15 at current pricing)

---

## 13. Testing Strategy

### 13.1 Test Layers

```
ULTRA-FAST TESTS (< 1 second)
├── Unit tests for services (protocol-based mocking)
├── Voting validation tests
└── Data model validation tests
    └── Run with: pytest --mode=ultra_fast

DEVELOPMENT TESTS (< 5 minutes)
├── Component tests (with API calls, but small payloads)
├── Multilingual response parsing
└── Memory service behavior
    └── Run with: pytest --mode=dev

CI/CD TESTS (< 15 minutes)
├── Integration tests (full Phase 1 + Phase 2)
├── Live endpoint testing (requires API key)
└── Multilingual coverage validation (EN, ES, ZH)
    └── Run with: pytest --mode=ci

FULL TESTS (30-45 minutes)
├── End-to-end experiment runs
├── All language combinations
└── All configuration combinations
    └── Run with: pytest --mode=full
```

### 13.2 Key Test Files

```
tests/
├── unit/
│   ├── test_fast_response_parsing.py       # Multilingual voting parsing
│   ├── test_fast_data_flows.py             # Service integration (mocked)
│   └── test_fast_*.py                      # 40+ fast tests (~0.04s)
│
├── component/
│   ├── test_voting_service.py              # Voting service integration
│   ├── test_memory_service.py              # Memory management
│   └── test_distribution_generator.py      # Payoff calculations
│
├── integration/
│   ├── test_phase1_execution.py            # Full Phase 1 flow
│   └── test_phase2_execution.py            # Full Phase 2 with services
│
└── snapshots/
    └── test_golden_results.py              # Baseline result validation
```


### 15.2 Debug Logging

```python
# Enable detailed logging
import logging
logging.basicConfig(level=logging.DEBUG)

# Check specific logger
logger = logging.getLogger("core.phase2_manager")
logger.setLevel(logging.DEBUG)

# Key log locations
# - core/phase2_manager.py: Overall flow
# - core/services/voting_service.py: Voting process
# - core/two_stage_voting_manager.py: Vote extraction
# - utils/selective_memory_manager.py: Memory updates
```

### 15.2 Transcript Logging

**Enable in config**:
```yaml
transcript_logging:
  enabled: true
  output_path: "transcripts/"
  include_instructions: true  # Expensive (adds ~5%)
  include_agent_responses: true  # Default, includes full responses
```

**Transcript contains**:
```json
{
  "experiment_id": "uuid",
  "timestamp": "2025-01-01T00:00:00",
  "interactions": [
    {
      "interaction_type": "phase1_discussion",
      "participant": "Alice",
      "prompt": "[Full prompt sent]",
      "response": "[Full response from agent]",
      "duration_seconds": 5.2
    },
    ...
  ]
}
```

---

## 16. Reference Implementation

**Quick Start**:
```bash
# Install dependencies
pip install -r requirements.txt

# Set API keys
export OPENAI_API_KEY="sk-..."
export OPENROUTER_API_KEY="sk-..."  # Optional

# Run quick test
python main.py config/fast.yaml results/test.json

# Run with custom config
python main.py config/my_experiment.yaml results/my_output.json

# Run tests
pytest --mode=ultra_fast  # 7 seconds
pytest --mode=dev        # 5 minutes
pytest --mode=ci         # 15 minutes
pytest --mode=full       # 30-45 minutes
```


